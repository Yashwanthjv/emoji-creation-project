{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88ea3ea0",
   "metadata": {},
   "source": [
    "# finall runned code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fad9fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 150ms/step\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import *\n",
    "import cv2\n",
    "from PIL import Image, ImageTk\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "import os\n",
    "\n",
    "# Load the pre-trained emotion detection model\n",
    "emotion_model = Sequential()\n",
    "emotion_model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48, 48, 1)))\n",
    "emotion_model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "emotion_model.add(Dropout(0.25))\n",
    "emotion_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "emotion_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "emotion_model.add(Dropout(0.25))\n",
    "emotion_model.add(Flatten())\n",
    "emotion_model.add(Dense(1024, activation='relu'))\n",
    "emotion_model.add(Dropout(0.5))\n",
    "emotion_model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "emotion_model.load_weights('model.h5')  # Load the weights of the model\n",
    "\n",
    "# Initialize OpenCV for webcam feed\n",
    "cv2.ocl.setUseOpenCL(False)\n",
    "emotion_dict = {0: \"Angry\", 1: \"Disgusted\", 2: \"Fearful\", 3: \"Happy\", 4: \"Neutral\", 5: \"Sad\", 6: \"Surprised\"}\n",
    "emoji_dist = {0: \"./emojis/angry.png\", 1: \"./emojis/disgusted.png\", 2: \"./emojis/fearful.png\", \n",
    "              3: \"./emojis/happy.png\", 4: \"./emojis/neutral.png\", 5: \"./emojis/sad.png\", \n",
    "              6: \"./emojis/surpriced.png\"}\n",
    "\n",
    "# Initialize variables for video capture\n",
    "global last_frame1\n",
    "last_frame1 = np.zeros((480, 640, 3), dtype=np.uint8)\n",
    "global cap1\n",
    "cap1 = cv2.VideoCapture(0)\n",
    "show_text = [0]\n",
    "\n",
    "# Function to capture and process webcam feed\n",
    "def show_vid():\n",
    "    global last_frame1\n",
    "    if not cap1.isOpened():\n",
    "        print(\"Can't open the camera\")\n",
    "    flag1, frame1 = cap1.read()\n",
    "    frame1 = cv2.resize(frame1, (600, 500))\n",
    "    bounding_box = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    gray_frame = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "    num_faces = bounding_box.detectMultiScale(gray_frame, scaleFactor=1.3, minNeighbors=5)\n",
    "    \n",
    "    for (x, y, w, h) in num_faces:\n",
    "        cv2.rectangle(frame1, (x, y-50), (x+w, y+h+10), (255, 0, 0), 2)\n",
    "        roi_gray_frame = gray_frame[y:y + h, x:x + w]\n",
    "        cropped_img = img_to_array(cv2.resize(roi_gray_frame, (48, 48)))  # Convert to array\n",
    "        cropped_img = np.expand_dims(cropped_img, axis=0)  # Add batch dimension\n",
    "        cropped_img = np.expand_dims(cropped_img, axis=-1)  # Add channel dimension\n",
    "        prediction = emotion_model.predict(cropped_img)\n",
    "        maxindex = int(np.argmax(prediction))\n",
    "        cv2.putText(frame1, emotion_dict[maxindex], (x+20, y-60), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        show_text[0] = maxindex\n",
    "    \n",
    "    if flag1 is not None:\n",
    "        last_frame1 = frame1.copy()\n",
    "        pic = cv2.cvtColor(last_frame1, cv2.COLOR_BGR2RGB)\n",
    "        img = Image.fromarray(pic)\n",
    "        imgtk = ImageTk.PhotoImage(image=img)\n",
    "        lmain.imgtk = imgtk\n",
    "        lmain.configure(image=imgtk)\n",
    "        lmain.after(10, show_vid)\n",
    "\n",
    "# Function to display emojis based on detected emotion\n",
    "def show_vid2():\n",
    "    emoji_path = emoji_dist[show_text[0]]\n",
    "    if os.path.exists(emoji_path):\n",
    "        frame2 = cv2.imread(emoji_path)\n",
    "        if frame2 is not None:\n",
    "            pic2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2RGB)\n",
    "            img2 = Image.fromarray(pic2)\n",
    "            imgtk2 = ImageTk.PhotoImage(image=img2)\n",
    "            lmain2.imgtk2 = imgtk2\n",
    "            lmain2.configure(image=imgtk2)\n",
    "    else:\n",
    "        print(f\"Emoji image not found at {emoji_path}\")\n",
    "    \n",
    "    lmain3.configure(text=emotion_dict[show_text[0]], font=('arial', 45, 'bold'))\n",
    "    lmain2.after(10, show_vid2)\n",
    "\n",
    "# Main function to create GUI\n",
    "if __name__ == '__main__':\n",
    "    root = tk.Tk()\n",
    "   \n",
    "    heading2 = Label(root, text=\"Photo to Emoji\", pady=20, font=('arial', 45, 'bold'), bg='black', fg='#CDCDCD')\n",
    "    heading2.pack()\n",
    "    \n",
    "    lmain = tk.Label(master=root, padx=50, bd=10)\n",
    "    lmain2 = tk.Label(master=root, bd=10)\n",
    "    lmain3 = tk.Label(master=root, bd=10, fg=\"#CDCDCD\", bg='black')\n",
    "    lmain.pack(side=LEFT)\n",
    "    lmain.place(x=50, y=250)\n",
    "    lmain3.pack()\n",
    "    lmain3.place(x=960, y=250)\n",
    "    lmain2.pack(side=RIGHT)\n",
    "    lmain2.place(x=900, y=350)\n",
    "    \n",
    "    root.title(\"Photo To Emoji\")\n",
    "    root.geometry(\"1400x900+100+10\")\n",
    "    root.configure(bg='black')\n",
    "    \n",
    "    exitbutton = Button(root, text='Quit', fg=\"red\", command=root.destroy, font=('arial', 25, 'bold'))\n",
    "    exitbutton.pack(side=BOTTOM)\n",
    "    \n",
    "    # Start the Tkinter main loop\n",
    "    root.after(0, show_vid)\n",
    "    root.after(0, show_vid2)\n",
    "    root.mainloop()\n",
    "\n",
    "    # Release the webcam and destroy all windows upon quitting\n",
    "    cap1.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b31291c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
